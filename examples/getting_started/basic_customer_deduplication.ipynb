{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Deduplication with RowVoi\n",
    "\n",
    "## Business Problem\n",
    "\n",
    "Your company has a customer database that has grown over time through multiple sources:\n",
    "- Website registrations\n",
    "- Trade show sign-ups  \n",
    "- Sales team entries\n",
    "- Partner referrals\n",
    "\n",
    "**The Problem:** You suspect many customers appear multiple times with slight variations in their information. This leads to:\n",
    "- âŒ Duplicate marketing emails (annoying customers)\n",
    "- âŒ Inflated customer counts (wrong metrics)\n",
    "- âŒ Wasted marketing budget\n",
    "- âŒ Poor customer experience\n",
    "\n",
    "**The Solution:** Use RowVoi to intelligently identify which customer fields to check to find and resolve duplicates efficiently.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. ğŸ¯ **Find minimal distinguishing fields** - Which customer attributes actually matter for deduplication?\n",
    "2. ğŸ” **Interactive disambiguation** - How to resolve ambiguous cases step-by-step\n",
    "3. ğŸ’° **Cost-aware selection** - Balance accuracy vs. effort when some fields are expensive to verify\n",
    "4. ğŸ“Š **Measure success** - Quantify the impact of your deduplication strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from rowvoi import (\n",
    "    DisambiguationSession,\n",
    "    GreedyCoveragePolicy,\n",
    "    find_key,\n",
    ")\n",
    "\n",
    "# Load our customer database\n",
    "df = pd.read_csv('../data/customers_sample.csv')\n",
    "print(f\"ğŸ“Š Customer Database: {len(df)} records\")\n",
    "print(f\"ğŸ“‹ Fields: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's spot the duplicates manually first\n",
    "\n",
    "Looking at the data, can you see the potential duplicates? This is exactly what RowVoi helps automate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look for obvious duplicates by examining similar names\n",
    "print(\"ğŸ” Records with similar names:\")\n",
    "print(\"\\nJohn Smith entries:\")\n",
    "print(df[df['last_name'] == 'Smith'].to_string())\n",
    "\n",
    "print(\"\\nSarah Johnson entries:\")\n",
    "print(df[df['last_name'] == 'Johnson'].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find Minimal Distinguishing Fields\n",
    "\n",
    "**Business Question:** *Which customer fields do we actually need to check to identify duplicates reliably?*\n",
    "\n",
    "Checking every field is expensive and time-consuming. RowVoi finds the minimal set that distinguishes all customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we suspect these customers might be duplicates\n",
    "suspicious_customers = [0, 1, 2, 4, 6, 9, 11, 13, 15, 17]\n",
    "\n",
    "print(f\"ğŸ¯ Analyzing {len(suspicious_customers)} potentially duplicate customers\")\n",
    "print(\"Customer records to distinguish:\")\n",
    "print(df.loc[suspicious_customers][['first_name', 'last_name', 'email', 'phone', 'company']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimal set of fields needed to distinguish these customers\n",
    "minimal_fields = find_key(df, suspicious_customers, strategy=\"greedy\")\n",
    "\n",
    "print(f\"âœ… Minimal distinguishing fields: {minimal_fields}\")\n",
    "print(f\"ğŸ“Š Only need to check {len(minimal_fields)} out of {len(df.columns)} fields!\")\n",
    "\n",
    "# Let's see why these fields work\n",
    "print(\"\\nğŸ” How these fields distinguish customers:\")\n",
    "print(df.loc[suspicious_customers][minimal_fields].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cost-Aware Field Selection\n",
    "\n",
    "**Business Reality:** Some fields are expensive to verify:\n",
    "- ğŸ“§ Email: Easy (already have)\n",
    "- ğŸ“ Phone: Moderate (might need to call)\n",
    "- ğŸ  Address: Expensive (requires address validation service)\n",
    "- ğŸ¢ Company: Very expensive (requires manual research)\n",
    "\n",
    "Let's find the most cost-effective approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define realistic costs for verifying each field\n",
    "field_costs = {\n",
    "    'first_name': 0.10,     # Very cheap - already have\n",
    "    'last_name': 0.10,      # Very cheap - already have\n",
    "    'email': 0.25,          # Cheap - easy to verify\n",
    "    'phone': 1.00,          # Moderate - might need to call\n",
    "    'address': 2.50,        # Expensive - address validation API\n",
    "    'city': 0.50,           # Moderate - part of address\n",
    "    'state': 0.25,          # Cheap - standardized\n",
    "    'zip_code': 0.50,       # Moderate - validation needed\n",
    "    'company': 5.00,        # Very expensive - manual research\n",
    "    'registration_date': 0.10  # Very cheap - already have\n",
    "}\n",
    "\n",
    "print(\"ğŸ’° Field verification costs:\")\n",
    "for field, cost in field_costs.items():\n",
    "    print(f\"  {field}: ${cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most cost-effective distinguishing fields\n",
    "cost_effective_fields = find_key(df, suspicious_customers, costs=field_costs, strategy=\"greedy\")\n",
    "\n",
    "# Calculate total costs\n",
    "minimal_cost = sum(field_costs[field] for field in minimal_fields)\n",
    "cost_effective_cost = sum(field_costs[field] for field in cost_effective_fields)\n",
    "\n",
    "print(\"ğŸ“Š Cost Comparison:\")\n",
    "print(f\"  Minimal fields: {minimal_fields}\")\n",
    "print(f\"  Cost: ${minimal_cost:.2f} per customer\")\n",
    "print(f\"  \\n  Cost-effective fields: {cost_effective_fields}\")\n",
    "print(f\"  Cost: ${cost_effective_cost:.2f} per customer\")\n",
    "print(f\"  \\nğŸ’¡ Savings: ${(minimal_cost - cost_effective_cost):.2f} per customer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Customer Resolution\n",
    "\n",
    "**Real-World Scenario:** You're processing customer records and find potential duplicates. Instead of checking all fields, RowVoi guides you to ask the most informative questions first.\n",
    "\n",
    "Let's simulate resolving a duplicate case step-by-step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate: We found these customers that might be the same person\n",
    "duplicate_candidates = [0, 1]  # John Smith records that look similar\n",
    "\n",
    "print(\"ğŸš¨ Potential duplicate detected!\")\n",
    "print(\"These customers might be the same person:\")\n",
    "print(df.loc[duplicate_candidates][['first_name', 'last_name', 'email', 'phone', 'company']].to_string())\n",
    "\n",
    "# Create a policy that considers costs\n",
    "policy = GreedyCoveragePolicy(costs=field_costs, objective=\"entropy\")\n",
    "\n",
    "# Start an interactive session\n",
    "session = DisambiguationSession(\n",
    "    df,\n",
    "    duplicate_candidates,\n",
    "    policy=policy,\n",
    "    feature_costs=field_costs\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ¯ Starting disambiguation with {len(duplicate_candidates)} candidates\")\n",
    "print(f\"ğŸ“Š Initial uncertainty: {session.state.entropy:.2f} bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first recommended field to check\n",
    "suggestion = session.next_question()\n",
    "print(f\"\\nğŸ’¡ RowVoi recommends checking: '{suggestion.col}'\")\n",
    "print(f\"   Expected value: {suggestion.score:.3f}\")\n",
    "print(f\"   Cost: ${suggestion.marginal_cost:.2f}\")\n",
    "\n",
    "# Show the values for this field\n",
    "print(f\"\\nğŸ“‹ Values for '{suggestion.col}':\")\n",
    "for idx in duplicate_candidates:\n",
    "    value = df.loc[idx, suggestion.col]\n",
    "    print(f\"   Customer {idx}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate checking the recommended field\n",
    "# Let's say we're trying to verify customer 0 (first John Smith)\n",
    "true_customer = duplicate_candidates[0]\n",
    "observed_value = df.loc[true_customer, suggestion.col]\n",
    "\n",
    "# Record our observation\n",
    "step = session.observe(suggestion.col, observed_value)\n",
    "\n",
    "print(f\"âœ… Checked '{suggestion.col}' = '{observed_value}'\")\n",
    "print(f\"ğŸ“Š Uncertainty reduced: {step.entropy_before:.2f} â†’ {step.entropy_after:.2f} bits\")\n",
    "print(f\"ğŸ’° Cost: ${step.cost:.2f}\")\n",
    "print(f\"\\nğŸ¯ Remaining candidates: {len(session.state.candidate_rows)}\")\n",
    "print(f\"ğŸ† Unique identification: {session.state.is_unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Measure Business Impact\n",
    "\n",
    "Let's calculate the real business value of this deduplication strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business impact calculation\n",
    "total_customers = len(df)\n",
    "estimated_duplicates = 8  # Based on our manual inspection\n",
    "duplicate_rate = estimated_duplicates / total_customers\n",
    "\n",
    "# Costs of NOT deduplicating\n",
    "marketing_cost_per_customer = 25.00  # Cost per marketing campaign per customer\n",
    "campaigns_per_year = 12\n",
    "wasted_marketing = estimated_duplicates * marketing_cost_per_customer * campaigns_per_year\n",
    "\n",
    "# Costs of our deduplication approach\n",
    "verification_cost_per_customer = cost_effective_cost\n",
    "deduplication_cost = suspicious_customers.__len__() * verification_cost_per_customer\n",
    "\n",
    "print(\"ğŸ“Š BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ğŸ“ˆ Total customers: {total_customers:,}\")\n",
    "print(f\"ğŸ” Estimated duplicates: {estimated_duplicates}\")\n",
    "print(f\"ğŸ“Š Duplication rate: {duplicate_rate:.1%}\")\n",
    "print()\n",
    "print(f\"ğŸ’¸ Annual cost of duplicates: ${wasted_marketing:,.2f}\")\n",
    "print(f\"ğŸ’° One-time deduplication cost: ${deduplication_cost:.2f}\")\n",
    "print(f\"ğŸ† Net annual savings: ${wasted_marketing - deduplication_cost:,.2f}\")\n",
    "print(f\"ğŸ“ˆ ROI: {((wasted_marketing - deduplication_cost) / deduplication_cost * 100):.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Production Implementation Strategy\n",
    "\n",
    "Based on our analysis, here's your recommended approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš€ PRODUCTION STRATEGY\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"\\n1ï¸âƒ£ Primary deduplication fields: {cost_effective_fields}\")\n",
    "print(f\"   ğŸ’° Cost per verification: ${cost_effective_cost:.2f}\")\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ Automated workflow:\")\n",
    "print(\"   â€¢ Run weekly scans for potential duplicates\")\n",
    "print(\"   â€¢ Use RowVoi to prioritize which records to investigate\")\n",
    "print(\"   â€¢ Focus on high-value customers first\")\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ Expected results:\")\n",
    "print(f\"   â€¢ Eliminate ~{estimated_duplicates} duplicate records\")\n",
    "print(f\"   â€¢ Save ${wasted_marketing:,.2f} annually in wasted marketing\")\n",
    "print(\"   â€¢ Improve customer experience (no duplicate emails)\")\n",
    "print(\"   â€¢ Get accurate customer metrics\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Next steps:\")\n",
    "print(\"   1. Implement this strategy on your full customer database\")\n",
    "print(\"   2. Set up monitoring for new duplicates\")\n",
    "print(\"   3. Train your team on the interactive resolution process\")\n",
    "print(\"   4. Measure and track your deduplication success metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "ğŸ¯ **Smart Field Selection**: RowVoi identified that you only need to check 1-2 key fields instead of all 10 customer attributes.\n",
    "\n",
    "ğŸ’° **Cost Optimization**: By considering verification costs, you can save money while maintaining accuracy.\n",
    "\n",
    "ğŸ” **Interactive Resolution**: For ambiguous cases, RowVoi guides you to ask the most informative questions first.\n",
    "\n",
    "ğŸ“Š **Measurable Impact**: Clear ROI calculation shows the business value of systematic deduplication.\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for more?** Check out other examples:\n",
    "- `business_use_cases/survey_optimization.py` - Optimize questionnaire design\n",
    "- `advanced_algorithms/` - Deep dive into algorithmic techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}